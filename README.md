 ğŸ“‹ ì†Œê°œ
---
![1](https://user-images.githubusercontent.com/104749023/183792578-7aac5169-8e8d-4af9-afd3-0da508003fd9.PNG)


- Resnet50ì„ í™œìš©í•´ ì´ë¯¸ì§€ ë¶„ë¥˜ ë”¥ëŸ¬ë‹ì„ í–ˆìŠµë‹ˆë‹¤. 


# ëœë“œë§ˆí¬ ì´ë¯¸ì§€ ë¶„ë¥˜
## ê°œìš”
Deep Learning ê¸°ë°˜ìœ¼ë¡œ ì´ë¯¸ì§€ ë¶„ë¥˜ì— ë„ì „í•´ë³´ê¸° ìœ„í•´ ë°ì´ì½˜ ê²½ì§„ëŒ€íšŒë¥¼ ì°¸ì—¬í–ˆìŠµë‹ˆë‹¤.

[ë°ì´ì½˜/ ëœë“œë§ˆí¬ ë¶„ë¥˜ AI ê²½ì§„ëŒ€íšŒ](https://dacon.io/competitions/official/235585/overview/description)


## ë°ì´í„° ìˆ˜ì§‘
ëŒ€íšŒì—ì„œëŠ” ë°ì´ì½˜ì—ì„œ ì œê³µí•œ ë°ì´í„°ê°€ ìˆì—ˆì§€ë§Œ í˜„ì¬ëŠ” ë‹¤ìš´ë¡œë“œê°€ ë¶ˆê°€ëŠ¥í•¨. Q&Aë¥¼ ì‚´í´ë³¸ ê²°ê³¼ AI Hubì—ì„œ ë‹¤ìš´ë¡œë“œê°€ ê°€ëŠ¥í•œê²ƒìœ¼ë¡œ í™•ì¸í–ˆìŠµë‹ˆë‹¤.

[AI Hub/ ëœë“œë§ˆí¬ ì´ë¯¸ì§€](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=realm&dataSetSn=56)

ì „ì²´ ë°ì´í„°ëŠ” 12TBë¡œ í•™ìŠµí•˜ëŠ” ì…ì¥ì—ì„œ ë‹¤ë£¨ê¸°ì— í¬ê¸° ë•Œë¬¸ì— ê°€ì¥ ì‘ì€ ì§€ì—­ë‹¨ìœ„ì¸ ì„¸ì¢…ì‹œ ë°ì´í„°ë§Œ í™œìš©í–ˆìŠµë‹ˆë‹¤.

- ì´ 48 GB
- ì‚¬ì§„í¬ê¸°: 4032 x 3024
- Class: 84ê°œ
- Training(12396ì¥)ê³¼ Validation(1504ì¥)ì´ë¯¸ì§€ê°€ ë‚˜ëˆ„ì–´ì ¸ ìˆìŠµë‹ˆë‹¤.


## ğŸ¯ ê²°ê³¼

|Accuracy|pyTorch|Resnet50|
|---|------|---|
|Train|99.85%|99.42%|
|Validation|85.17%|96.68%

![Result](https://user-images.githubusercontent.com/100823210/183580705-a1af4afb-6608-4389-b921-3e8f287cb751.png)

ì¼ë¶€ í–¥êµë‚˜ ì„œì›ì™€ ê°™ì€ ì´ë¯¸ì§€ëŠ” ì˜ ë¶„ë¥˜í•˜ì§€ ëª»í•˜ëŠ” ëª¨ìŠµì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![actual pred](https://user-images.githubusercontent.com/100823210/183580924-f71cab66-f252-409b-bccf-3e5376cf1677.png)


## ì „ì²˜ë¦¬
### ì‚¬ì „ì‘ì—…
Google Colabì—ì„œëŠ” ìˆ˜ì§‘ëœ ë°ì´í„°ì˜ ì—…ë¡œë“œê°€ í˜ë“¤ê¸°ë•Œë¬¸ì— Local ì»´í“¨í„°ì—ì„œ OpenCVë¥¼ ì´ìš©í•˜ì—¬ ë°ì´í„° í¬ê¸°ë¥¼ ì›ë³¸í¬ê¸°ì˜ 0.1ë°°ë¡œ ì¤„ì˜€ìŠµë‹ˆë‹¤.
```python
import cv2

img = cv2.imread(os.path.join(region_dir, cls, fname))
resized_img = cv2.resize(img, (0, 0), fx=0.1, fy=0.1, interpolation=cv2.INTER_AREA)
cv2.imwrite(os.path.join(target_dir, fname), resized_img)
```

### Transform
#### Resize
Resize í¬ê¸°ì— ë”°ë¥¸ Accuracy ì¸¡ì •ì„ ìœ„í•´ ì•„ë˜ 3ê°€ì§€ ê°’ìœ¼ë¡œ ë³€ê²½í•˜ë©° ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.
- 256x256, 128x128, 64x64

#### Normalize
ì´ë¯¸ì§€ë„·ì˜ mean, stdê°’ì„ ì‚¬ìš©í•´ë„ ê´œì°®ì•˜ì§€ë§Œ ì¢€ ë” Accuracyë¥¼ ì˜¬ë¦¬ê¸° ìœ„í•´ ì•„ë˜ í•¨ìˆ˜ë¥¼ í™œìš©í•˜ì—¬ ë°ì´í„°ì˜ Normalize ê°’ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.
```python
def get_mean_and_std(dataloader):
    channels_sum, channels_squared_sum, num_batches = 0, 0, 0
    for data, _ in dataloader:
        # Mean over batch, height and width, but not over the channels
        channels_sum += torch.mean(data, dim=[0,2,3])
        channels_squared_sum += torch.mean(data**2, dim=[0,2,3])
        num_batches += 1
    
    mean = channels_sum / num_batches

    # std = sqrt(E[X^2] - (E[X])^2)
    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5

    return mean, std
```

### Dataset & DataLoader

|Dataset & DataLoader|ì„¤ëª…|
|------|---|
|Listì²˜ëŸ¼ ì§ì ‘ indexí•˜ëŠ” ë°©ë²•|ì§ì ‘ ì‘ì„±í•  ìˆ˜ë„ ìˆì–´ì„œ ëŒ€ëŸ‰ì˜ ì´ë¯¸ì§€ íŒŒì¼ì„ í•œ ë²ˆì— ë©”ëª¨ë¦¬ì— ì €ì¥í•˜ì§€ ì•Šê³ , í•„ìš”í•  ë•Œë§ˆë‹¤ ì½ì–´ì„œ í•™ìŠµí•˜ëŠ”ë“¯|
|DataLoaderë¥¼ í†µí•´ ìˆœíšŒí•˜ê¸°|í•™ìŠµì„ ì§„í–‰í•˜ëŠ” forë¬¸ì— ì‚¬ìš©ë˜ì—ˆìœ¼ë©° generator ì‚¬ìš© ë˜ì–´ ê° iteration ë§ˆë‹¤ batch size ë§Œí¼ ê°€ì ¸ì™€ì„œ ì‚¬ìš©í•˜ëŠ” ê²ƒ|


ImageFolderì™€ DataLoaderë¥¼ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.
    - í´ë”ì˜ êµ¬ì¡°ê°€ ImageFolderë¥¼ ì‚¬ìš©í•˜ê¸° ì‰½ê²Œ êµ¬ì„±ë˜ì–´ìˆìŠµë‹ˆë‹¤.
    
    
    
```python
image_datasets = {x: ImageFolder(root=os.path.join(data_dir, x),
                                 transform=transform[x]) for x in transform.keys()}
dataloaders = {x: DataLoader(image_datasets[x],
                             batch_size=BATCH_SIZE,
                             shuffle=True,
                             num_workers=2) for x in transform.keys()}
```

## ğŸ” ëª¨ë¸ë§
### ì „ì´í•™ìŠµ
Resnet50ì„ ì´ìš©í•œ ì „ì´í•™ìŠµì„ ê³„íší–ˆìŠµë‹ˆë‹¤. (requires_grad = FalseëŠ” conv3_xê¹Œì§€ ì ìš©)
![Resnet50](https://user-images.githubusercontent.com/100823210/183578724-b8298ea1-5336-4580-99b0-1c6109194491.png)

#### Resnet50ì„ ì‚¬ìš©í•œ ì´ìœ 
1. í•™ìŠµ ë‚œì´ë„ê°€ ë§¤ìš° ë‚®ì•„ì§‘ë‹ˆë‹¤.
2. ê¹Šì´ê°€ ê¹Šì–´ì§ˆìˆ˜ë¡ ë†’ì€ ì •í™•ë„ í–¥ìƒì„ ë³´ì…ë‹ˆë‹¤.
3. ë§ì€ ìˆ˜ì˜ Layerë¥¼ ëˆ„ì í•˜ì—¬ ê¹Šì€ Networkë¥¼ ì„¤ê³„í•  ë•Œ ì—¬ëŸ¬ ë¬¸ì œê°€ ë°œìƒí•˜ëŠ” CNNë¬¸ì œë¥¼ ë³´ì™„í•©ë‹ˆë‹¤.

### Sweeps ( weights & Biases)
webì—ì„œ ê²°ê³¼ì— ëŒ€í•œ ì‹œê°í™” ê¸°ëŠ¥ì„ ì§€ì›í•˜ê¸°ì— sweepsë¥¼ í†µí•œ Accuraryì™€ Loss function ì‹œê°í™”

### ì˜µí‹°ë§ˆì´ì €
Adamì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.

### ìŠ¤ì¼€ì¥´ëŸ¬
7ë²ˆì§¸ Epochë§ˆë‹¤ 0.1ë°°ì”© ë‚®ì•„ì§€ê²Œ ì„¤ì •í–ˆìŠµë‹ˆë‹¤.
```python
# Decay LR by a factor of 0.1 every 7 epochs
exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=7, gamma=0.1)
```

## ì„±ëŠ¥ ê°œì„ 
ìµœì ì˜ íŒŒë¼ë¯¸í„° íŠœë‹ê°’ì„ ì°¾ê¸°ìœ„í•´ Weights & Biasesì˜ Sweeps ê¸°ëŠ¥ì„ ì´ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ë³€ìˆ˜ë¥¼ ë³€ê²½í•˜ì—¬ ë°˜ë³µ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.

[Hyperparameter-Sweeps](https://wandb.ai/zbooster/Hyperparameter-Sweeps?workspace=user-zbooster)

## âš™ï¸ ì˜ë¬¸ì 
Ephochsë¥¼ ëŒë¦¬ë©´ì„œ Train Accuracyê°€ 100%ê°€ ë‚˜ì˜¤ëŠ” ê²½ìš°ë¥¼ ë´¤ìŠµë‹ˆë‹¤.
    - Accuracyê°€ 100%ê°€ ë‚˜ì˜¤ë©´ ë°ì´í„°ë¥¼ í•œë²ˆ ì˜ì‹¬í•´ì•¼ í•©ë‹ˆë‹¤.
        - ì„¸ì¢…ì‹œ ë°ì´í„°ë¡œ ì¶•ì†Œí•˜ë©´ì„œ ë°ì´í„°ê°€ overfittingëœ ë¶€ë¶„ì€ ì—†ëŠ”ì§€ í™•ì¸í•  ì˜ˆì •ì…ë‹ˆë‹¤.
        
## ğŸ“– ê´€ë ¨ ìë£Œ
- ë§ˆì´í¬ë¡œì†Œí”„íŠ¸ ì—°êµ¬ì› Kaiming He ì™¸ 3ì¸(2015), Deep Residual Learning for Image Recognition
    - https://arxiv.org/pdf/1512.03385.pdf
- AI ì—°êµ¬ì› Aroddary, (ResNet) Deep residual learning for image recognition ë²ˆì—­ ë° ì¶”ê°€ ì„¤ëª…ê³¼ Keras êµ¬í˜„
    - https://sike6054.github.io/blog/paper/first-post/
    
## ğŸ¤² íŒ€ì› ì†Œê°œ 
|íŒ€ì›|ì—°ë½|
|------|---|
|ê¹€ì†¡í˜„|[G.mail](zpaladin1213@gmail.com) â”‚ [Velog](https://velog.io/@zbooster)|
|ê¹€í•´ì†”|[G.mail](lunchtime99@gmail.com) â”‚ [Velog](https://velog.io/@kim_haesol)|
